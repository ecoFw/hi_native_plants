---
title: Webscraping Native Plants Hawaii

---

https://web.archive.org/web/20240520100248/http://nativeplants.hawaii.edu/


Can use the ruby package 'wayback_machine_downloader'.



```{r wb, eval = TRUE, echo = TRUE}

library(pacman)
p_load(rvest, magrittr)

extract_spp_name <- function(x){
    out <- strsplit(x, "-")[[1]][1]
    out <- strsplit(out, " ")[[1]]
    out <- out[out != "\r"]
    out <- out[!(grepl("var", out))]
    out <- paste(out, collapse = "_")
    return(out)
}


urls <- paste0(rep("http://nativeplants.hawaii.edu/plant/index/page/", 24), seq(1, 24))

html <- lapply(urls, read_html)

text <- lapply(html, function(x) x %>% html_elements("p") %>% html_text2())
spp <- lapply(text, function(x) x[grepl("View Profile", x)])
spp.name <- lapply(spp, 
                   function(x) 
                       unlist(lapply(x, function(x) 
                           lapply(x, extract_spp_name))))
spp.page <- unlist(spp.name)
spp.page[spp.page == "Vigna_o"] <- "Vigna_o-wahuensis"
spp.page[spp.page == "Adiantum_capillus"] <- "Adiantum_capillus-veneris"
spp.page[spp.page == "Bidens_micrantha_subsp._micrantha"] <- "Bidens_micrantha_micrantha"

spp.page <- paste0("http://nativeplants.hawaii.edu/plant/view/", 
                  spp.page)

plant.html <- list()
for (i in seq_along(spp.page)){
    plant.html[[i]] <- read_html(spp.page[[i]])
}

plant.html <- read_html(spp.page[[227]])
plant.txt <- plant.html %>% html_elements("div") %>% html_text2()



```
